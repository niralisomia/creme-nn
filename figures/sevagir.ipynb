{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f75f21f5-6987-4872-8b5f-4280b1c0bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../creme/')\n",
    "import custom_model\n",
    "import shuffle\n",
    "import creme\n",
    "import utils\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyranges as pr\n",
    "import shutil\n",
    "import pickle\n",
    "import kipoiseq\n",
    "from itertools import combinations\n",
    "import scipy\n",
    "import os\n",
    "import gene as bgene\n",
    "import shuffle\n",
    "from scipy.stats import pearsonr\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e396dd34-c5b7-4f33-844e-c0bbaf1ce427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class Enformer:\n",
    "\n",
    "  def __init__(self):\n",
    "    tfhub_url = 'https://tfhub.dev/deepmind/enformer/1'\n",
    "    os.environ['TFHUB_CACHE_DIR'] = '.'\n",
    "    self._model = hub.load(tfhub_url).model\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    predictions = self._model.predict_on_batch(inputs)\n",
    "    return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "  @tf.function\n",
    "  def contribution_input_grad(self, input_sequence,\n",
    "                              target_mask, output_head='human'):\n",
    "    input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "    target_mask_mass = tf.reduce_sum(target_mask)\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(input_sequence)\n",
    "      prediction = tf.reduce_sum(\n",
    "          target_mask[tf.newaxis] *\n",
    "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
    "\n",
    "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
    "    input_grad = tf.squeeze(input_grad, axis=0)\n",
    "    return tf.reduce_sum(input_grad, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b92d30ec-3553-4b04-9334-96929c9fc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model.Enformer()\n",
    "# model = Enformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b12a2d36-9af3-463e-9959-9bb9f173e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_parser = utils.SequenceParser('../data/GRCh38.primary_assembly.genome.fa')\n",
    "x = seq_parser.extract_seq_centered('chr1', 20000000, '+', 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4487ee3e-5423-4d09-9040-2f5c8badd22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 5313)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions = model.predict_on_batch(x[np.newaxis])['human'][0]\n",
    "predictions = model.predict(x[np.newaxis])[0]\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a9b3a78-e01e-40fb-9d98-f4ca1ad61cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = np.zeros_like(predictions)\n",
    "for idx in [447, 448]:\n",
    "  # target_mask[idx, 4828] = 1\n",
    "  target_mask[idx, 5111] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9da45bc1-4f47-47ba-b3bc-bd867ba7cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196608, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c8fd90d-579f-4d55-9eab-45ef9315152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.pad(x[np.newaxis], ((0, 0), (model.pseudo_pad // 2, model.pseudo_pad // 2), (0, 0)), 'constant')\n",
    "\n",
    "contribution_scores = model.contribution_input_grad(x.astype(np.float32), target_mask).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0f48752-95d4-4cfd-8ccc-2a4781578e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746ae13-6836-4613-9132-4e43962a626a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
